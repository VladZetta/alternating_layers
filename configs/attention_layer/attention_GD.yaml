embed_dim: 16
seq_len: 10
batch_size: 64
total_samples: 10000
num_epochs: 20    
learning_rate: 0.5
save_dir: "results/attention_layer"
mixed: false           # Use mixed optimization (FO + SO)
optimizer: "SGD"        # Optimizer for FO optimizer
variant: "GradReg"    # Variant for SO optimizer
method: "GD"        # Optimizer for FO optimizer
L: 1.0                # Lipschitz constant for SO optimizer
reg: 0.01             # Regularization parameter for SO optimizer





