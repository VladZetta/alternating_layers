embed_dim: 16
seq_len: 10
batch_size: 64
total_samples: 10000
num_epochs: 50  
learning_rate: 0.1
save_dir: "results/attention_layer"
mixed: true           # Use mixed optimization (FO + SO)
optimizer: "Adam"        # Optimizer for FO optimizer
variant: "GradReg"    # Variant for SO optimizer
method: "Adam+GradReg"        # Optimizer for FO optimizer
L: 1.0                # Lipschitz constant for SO optimizer
reg: 0.01             # Regularization parameter for SO optimizer





